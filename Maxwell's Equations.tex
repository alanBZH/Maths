%These comments were left for any intrepid scholars who may examine this file after me
%   -Confuted / Matt Hansen

%A few commonly used constants, to cut down on typing and increase clarity
\def\eps0{\ensuremath{\epsilon _0}}
\def\2pieps0{\ensuremath{2\pi \epsilon _0}}
\def\4pieps0{\ensuremath{4\pi \epsilon _0}}
\def\k{\ensuremath{\displaystyle \frac{1}{4\pi \epsilon _0}}}
\def\muz{\ensuremath{\mu_0}} %For some reason, \mu0 gave me an error - probably because \mu is a command

%Define a closed integral construct. I had some help with making this one look nice
\def\cint#1{\ensuremath{\displaystyle\underset{\substack{\text{\tiny{closed}}\\\text{\tiny{surface}}}}{\oint} \mspace{-0.1 mu} #1}}

%Define symbols for flux, just to make sure it stays consistent throughtout the paper
\def\phie{\ensuremath{\phi_E}}
\def\phib{\ensuremath{\phi_B}}

%Define the derivatives I'll be using, so I don't have to do all the typing every time
\def\dA{\ensuremath{\emph{d}\vec{A}}}
\def\dB{\ensuremath{\emph{d}\vec{B}}}
\def\ds{\ensuremath{\emph{d}\vec{s}}}
\def\dt{\ensuremath{\emph{dt}}}
\def\dphie{\ensuremath{\emph{d}\phie}}
\def\dphib{\ensuremath{\emph{d}\phib}}

\documentclass[12pt]{article}
\title{Maxwell's Equations}
\author{Matt Hansen}

\usepackage{amsmath}
\usepackage[pdftex]{graphicx}

\begin{document}
\maketitle
\newpage
\tableofcontents
\newpage
\section{Introduction}
\indent If asked, most people outside a physics department would not be able to identify Maxwell's equations, nor would they be able to state that they dealt with electricity and magnetism. However, Maxwell's equations have many very important implications in the life of a modern person, so much so that people use devices that function off the principles in Maxwell's equations every day without even knowing it.
\section{The basics}

\subsection{Static charges}

\indent In order to understand Maxwell's equations, it is necessary to understand some basic things about electricity and magnetism first. Static electricity is easy to understand, in that it is just a charge which, as its name implies, does not move until it is given the chance to ``escape'' to the ground. Amounts of charge are measured in coulombs, abbreviated $C$. $1C$ is an extraordinary amount of charge, chosen rather arbitrarily to be the charge carried by $6.41418\cdot 10^{18}$ electrons. The symbol for charge in equations is $q$, sometimes with a subscript like $q_1$ or $q_{enc}$.

As children are taught in grade school, ``opposites attract, likes repel.'' This applies to both magnets and to charges; two negative charges will repel each other, as will two positive charges, but a positive and negative charge will attract each other. The force of this repulsion is given by Coulomb's Law,
\begin{equation}
\displaystyle F_E = \k \frac{q_1\cdot q_2}{r^2}
\end{equation}
where $F_E$ is obviously force due to charges, $\eps0$ is a constant called the electric permittivity of free space, and $r$ is the distance seperating these charges. \k is a constant, also known as $k$ or Coulomb's constant, expressed in terms of $\eps0$. $k$ has units of $\left(N\cdot m^2\right)/\left(C^2\right)$. It may seem arbitary to express $k$ in terms of $\pi$, but it is expressed that funny way for historical reasons that will become clearer later. If $F_E$ is negative, which happens only if $q_1$ and $q_2$ have different signs, it simply means the charges do not repel, but rather attract. Coulomb's Law is remarkably similar to the force of gravitational attraction, which is the same other than that charge is replaced by mass, and $k$ is replaced with a new constant, $g$.

That is useful for finding the attraction or repulsion between two charges, but is not as good if a third charge enters the problem. Because of this, it is useful to define electric fields. To understand electric fields, imagine taking a small positive test charge $q$ and using it to ``probe'' the force caused by some larger charge $Q$. Then, by dividing out charge $q$, we will have a number that represents the strength of the electric field, denoted $E$:
\begin{equation}
\displaystyle E = \frac{F_E}{q} = \k \frac{Q}{r^2}
\end{equation}
Because electric field point in the direction a positive test charge would move, fields move away from a positive charge and toward a negative charge. The units on $E$ are Newtons per coulomb.

\subsection{Moving charges}

\indent Imagine that charge was flowing through a conductor at the rate of $1C$ per second. This is defined as a current of one ampere, abbreviated amp, or $A$. The symbol for amps in an equation is $I$. From basic physics, work is defined as force times the distance moved perpendicular to the direction of the force: $W=F\times D$, and is measured in Joules. Joules are abbreviated $J$ and are a measurement of energy, with $1J$ being a force of one Newton applied over a distance of one meter: $1J=N\cdot m$. 

Electric fields are measured in Newtons per coulomb, but are not usually expressed like this; they are usually expressed in volts per meter. Voltage is a measure of electric potential - the amount of potential energy available per unit charge. Every point in space has an electric potential, with the general convention that a point infinitely far away from a charge has an electric potential of zero. If a charge of $1C$ is moved over a potential difference of $1V$, $1J$ of work will be done, so the definition of a volt, abbreviated $V$, is $1V=1J/C$. That is equivalent to $1V=N\cdot m/C$, so $1N/C=1V/m$, and the units are equivalent. 

\subsection{Magnetism}

\indent Ancient Greeks and Chinese discovered that certain types of rock, called loadstones, had mysterious properties which they could not explain. The rocks would attract small bits of iron, and when tied to a string and hung, would always point the same direction \cite{magnet}. Later scientists figured out that these rocks were magnets, and discovered some of the many properties of magnets that we are familiar with today. Magnets have two poles, labelled north and south; magnetic fields, largely analogous to electric fields, flow by convention from the north pole to the south pole. Magnetic field strength is measured in Gauss $(G)$ or Tesla $(T)$, with $1T=10^4G$. To get a feeling for this, Earth's magnetic field is a bit less than $1G$. The north and south poles of two magnets will attract each other, but the north and north poles or the south and south poles will repel, just like charges.

\subsection{Vector operations}

\indent Mathematically, this is going to get rather complex rather fast, but it is necessary to understand both basic vector operations and some calculus. A vector is made up of three components: an $x$, a $y$, and a $z$, written $\left\langle x,y,z\right\rangle$. A vector represents a magnitude (length), and direction. The magnitude of a vector alone, without direction, denoted $|\vec{V}|$, is called a scalar. If $V_x$ is defined as the $x$ component of $V$, and $V_y$ and $V_z$ are defined similarly, then vector magnitudes can be found by $|\vec{V}|=\sqrt{\vec{V}_x^2+\vec{V}_y^2+\vec{V}_z^2}$. Vector addition is defined as $\vec{A}+\vec{B}=\left\langle A_x+B_x,  A_y+B_y, A_z+B_z \right\rangle$. Vector subtraction has a similar definition. There are two defined types of vector multiplication: the dot product and the cross product. The dot product, written $\vec{A}\cdot \vec{B}$, is a scalar quantity representing the length of the projection of $\vec{A}$ onto $\vec{B}$ when their tails coincide. Mathematically, the dot product is usually calculated with $\vec{A}\cdot \vec{B}=|\vec{A}||\vec{B}|\cos{\theta}$ where $\theta$ is the smallest angle between $\vec{A}$ and $\vec{B}$. The other form of vector multiplication is the cross product. $\vec{A}\times \vec{B}$ produces a vector of magnitude $|\vec{A}||\vec{B}|\sin{\theta}$ in the direction perpendicular to both $\vec{A}$ and $\vec{B}$. Since there are two solutions to this, seperated by 180 degrees, the right hand rule is adopted to determine a unique solution. To apply the right hand rule, make a ``gun'' and point the index finger of the right hand in the direction of $\vec{A}$ and the middle finger of the right hand in the direction of $\vec{B}$; the thumb points in the direction of $\vec{A} \times \vec{B}$. Because of the right hand rule, $\vec{A} \times \vec{B} \neq \vec{B} \times \vec{A}$. Instead, $\vec{A} \times \vec{B} = -\vec{B} \times \vec{A}$, which makes sense. A vector that is said to be normal to a plain is simply a vector perpendicular to the plain, pointing outward if the plain is part of a closed surface. A unit vector is a vector with a magnitude of one.

\subsection{Calculus}

\indent The derivative of a changing quantity is defined as the \textit{instantaneous} rate at which it is changing. If the quantity were graphed with respect to time, this would be equivalent to the slope of the line drawn tangent to the graph at any given time. The derivative of a quantity $x$ with respect to time $t$ is written $\displaystyle \frac{dx}{dt}$ or, equivalently, $\displaystyle \frac{d}{dt} x$. The integral of a function or quantity is the same as taking the sum of the given quantity over all values in the range specified, which is actually the exact opposite of a derivative. The integral of the function $f(x)$ between $a$ and $b$ would be written $\displaystyle\int_a^b{f(x)dx}$. The $dx$ indicates that we are multiplying the value of f(x) at each value of x by some infinitely small value $dx$ to find the area of some infinitely small rectangle of height $f(x)$ and width $dx$, and adding the areas of all such rectangles in the interval $[a,b]$ to find the area under the curve of $f(x)$ between $a$ and $b$. If no limits are specified, the integral gives a function which can be used to find the value of an equivalent integral with limits, rather than just giving a value. While that may not be the most coherent definition, a real discussion of Calculus would take many pages. Remember that an integral is the sum of all of many very tiny contributions, and that a derivative is the instantaneous rate of change of a quantity. Also, note that $\displaystyle \frac{d}{dx} \int_0^x{f(t)dt}=\int{\left(\frac{d}{dx}f(x)\right)dx}=f(x)$.

\subsection{Flux}

\indent Finally, electric and magnetic flux, written \phie \ and \phib \ respectively (B is the letter used for magnetic fields), are defined as the amount of ``flow'' of the electric (or magnetic) field through a certain amount of area. Since that definition is confusing, a mathematical one might make more sense. Let \dA \ be a vector normal to a closed surface (such as a sphere), which is placed in space. The closed surface integral, which is denoted \cint{}, is simply the integral over all regions on the closed surface. Electric flux, \phie, is defined as $\phie=\cint{\vec{E}\cdot \dA}$, and magnetic flux, \phib, is defined as $\phib=\cint{\vec{B}\cdot \dA}$.

\section{History}

\indent Near the end of the eighteenth century, advancements began taking place in the fields of electricity and magnetism that led to the modern theories. In 1785, Coulomb developed equipment that experimentally confirmed what came to be known as Coulomb's law (1) \cite{Biggus}. In 1800, Volta created the first battery, and in 1820 Oersted noted that a compass was deflected by a wire with current flowing through it, which was the first time anyone had realized that electricity and magnetism are connected \cite{Biggus}. Ampere also did his first important work in 1820. Biot and Savart developed what came to be known as the Biot-Savart Law, relating the strength of a magnetic field to the current flowing through a wire and the distance from the wire:
\begin{equation}
d\vec{B}=\frac{\muz}{4\pi}\frac{i\times\vec{r}}{r^3}
\end{equation}

During the next fifty years, all of the ``big names'' made breakthroughs in the field and developed the equations that are used today. Gauss related electric flux to electric charge, and magnetic flux to magnetic charge, and Faraday related induced voltage to changing magnetic fields. Ampere also found a connection between magnetic fields and current flowing through a wire.

When Maxwell entered the picture in 1864, the field changed for good (no pun intended). Maxwell formulated equations representing the observations of Gauss, Faraday, and Ampere, in terms of twenty equations and twenty variables. He also noticed that there was a logical inconsistency in Ampere's ``law'' in that it did not give mathematically consistent results in circuits that contained capacitors. Maxwell determined that there was a missing term and worked out what it should be; this is now known as displacement current and represented the final piece in the laws of electricity and magnetism. Maxwell's equations were later simplified into four differential equations by Heaviside using vectors, forming the four laws known collectively today as ``Maxwell's equations'' \cite{Wikipedia}.

\section{Maxwell's Equations}

\subsection{Maxwell's Equations}

\indent The differential forms of Maxwell's equations as found by Heaviside, while completely valid, are now considered somewhat archaic, and have been replaced by the more useful (equivalent) integral forms. Each law is named according to the person(s) who originally discovered the connections represented by the equation. Here are the four equations:
\begin{eqnarray}
\text{Gauss' law for electricity:}& \displaystyle \cint{\vec{E}\cdot\dA}&=\frac{Q_{enc}}{\eps0}\\
\text{Gauss' law for magnetism:}& \displaystyle \cint{\vec{B}\cdot\dA}&=0\\
\text{Faraday's law:}& \displaystyle\oint{\vec{E}\cdot\ds}&=-\frac{\dphib}{\dt}\\
\text{Ampere-Maxwell law:}& \displaystyle\oint{\vec{B}\cdot\ds}&=\muz\eps0\frac{\dphie}{\dt}+\muz i_{enc}
\end{eqnarray}
Note: $\oint$ is used to specify a closed loop integral, also known as a line integral. It simply means that in the calculations, we must go all the way around the loop; we can't stop part way through or the equations won't be valid.

\subsection{Gauss' law for electricity}

\indent Gauss' law for electricity, more commonly simply refered to as Gauss' law, states that the closed surface integral of $\vec{E}\cdot\dA$ is equal to the charge enclosed by the surface divided by the electric permittivity of the material the charge is in. Generally, the electric permittivity, denoted $\epsilon$, is taken to be the electric permittivity of free (empty) space, and is written \eps0. ($\eps0\approx 8.85\cdot10^{-12} F/m$).

We are free to choose our ``surface'' - it's an imaginary construct for the purposes of doing the math, not a real entity. The most common surfaces chosen are spheres and cylinders, because mathematically, symmetry makes applying Gauss' law much easier, but theoretically, any closed surface can be chosen and it will give the exact same results.

Imagine a point charge of $+Q$ floating in space. Centered around this charge, construct a spherical Gaussian surface of radius $R$. Since the charge is centered in the sphere, the E field points radially outward and has the same magnitude at all points on the sphere. Remember that $\displaystyle E = \k \frac{Q}{r^2}$. Since in this example, $r=R$, this equation becomes $\displaystyle E = \k \frac{Q}{R^2}$. 

From the definition of electric flux, $\displaystyle \phie=\cint{\vec{E}\cdot \dA}$, so applying Gauss' law is a way of finding the electric flux through a surface due to a charge $Q$. \dA \ is a unit vector normal to the surface at all points, and represents a tiny portion of the surface area of the Gaussian surface. The closed surface integral of \dA \ is the surface area, $A$.

Again from the definition of electric flux,
\begin{eqnarray*}
\phie &=& \cint{\vec{E}\cdot\dA}\\
E &=& \k \frac{Q}{R^2}\\
\phie &=& \cint{\left(\k \frac{Q}{R^2}\right)\cdot\dA}\\
\end{eqnarray*}
Since $\vec{E}$ is pointing radially outward everywhere, it is always parallel to \dA, and $\vec{E}\cdot\dA$ becomes $(\vec{E})\dA$. Since $\vec{E}$ is constant at all points on the sphere, it can be moved outside the integral:
\begin{eqnarray*}
\phie &=& \left(\k \frac{Q}{R^2}\right)\cint{\dA}\\
\phie &=& \left(\k \frac{Q}{R^2}\right)A\\
\end{eqnarray*}
where A is the surface area of the sphere. However, the surface area of a sphere is simply $4\pi R^2$, so this becomes
\begin{eqnarray*}
\phie &=& \left(\k \frac{Q}{R^2}\right)\left(4\pi R^2\right)\\
\phie &=& \frac{Q}{\eps0}\\
\end{eqnarray*}
But this, of course, is simply Gauss' law! \phie \ is independent of the radius of the sphere, which may seem strange, since $\vec{E}$ clearly decreases at a rate $\propto 1/R^2$; however, since $\vec{E}$ points away from the charge, no matter how large the radius of the sphere is, the electric field will still penetrate it at some point, and the flux will \textit{have} to be the same. Mathematically, it works because $\phie$ is $\vec{E}$ multiplied by the surface area of the Gaussian surface; $\vec{E} \propto 1/R^2$, and $A\propto R^2$, so their product, \phie \ must be independent of $R$.

Imagine that, instead placing a charge of $+Q$ inside the Gaussian surface, we placed outside. Clearly the electric field still points away from the charge, and at some point, the electric field will pass through the Gaussian surface. On one side of the surface, this will give a negative flux - the electric field is entering the surface! But the electric field will have to leave the Gaussian surface on the other side, creating a positive flux. Since all the field lines that enter the surface must leave again - they don't just stop - the net electric flux will be zero, as predicted by Gauss' law.

Using arguments of symmetry, it is also possible to prove Gauss' law for Gaussian surfaces of other shapes, such as cylinders. It can also be used ``in reverse;'' by dividing both sides of the equation by $A$ after integrating, the electric field caused by various charge configurations can be found for all points in space. An example of this is finding the electric field at all points in space caused by an infinitely large plane of charge density $\rho$. It's done using a cylindrical Gaussian surface rather than a spherical one, and while the idea of an infinitely large plane is ridiculous, the results hold true as long as the distance from the plane at which the electric field is being calculated is significantly smaller than the size of the plane, and not near the edge.

\subsection{Gauss' law for magnetism}

Gauss' law for magnetism is remarkably similar to Gauss' law for electricity in form, but means something rather different. Imagine that a magnet was placed in space, and that a spherical Gaussian surface was constructed around it. 

Remember from the section on magnetism that magnetic fields ``flow,'' by convention, from the North pole of a magnet to the South pole. From the definition of magnetic flux, $\displaystyle \phib = \cint{\vec{B}\cdot\dA}$. Part of the magnetic field will not pierce the Gaussian surface - this portion of the field clearly will not contribute to the flux through the surface, so it can be ignored. The rest of the magnetic field lines will leave through the surface from the North pole of the magnet, but because the field flows from the North pole to the South pole, the same field lines will enter the surface again somewhere on the surface to go to the South pole. Since the flux going out is equal to the flux coming in, the net flux is zero, as indicated by Gauss' law for magnetism.

Suppose that instead the magnet was placed outside the Gaussian surface. The same argument applies: any part of the magnetic field that enters the surface will have to leave again through the surface, since it is closed. The positive flux will equal the negative flux, they'll cancel, and the net flux will be zero. Again, this matches what was predicted by Gauss' law.

Pretend that a special magnet with only a North pole, and no South pole, existed. This would be called a magnetic monopole. All the magnetic field lines would point away from this theoretical magnetic monopole, just like the electric field lines point away from a positive charge $Q$. If a Gaussian surface was constructed around this monopole, there would obviously be a positive flux going through the surface, because the magnetic field is leaving, and it isn't coming back in! Gauss' law for magnetism, however, very clearly says that the flux should be zero! This means that according to Gauss, there can be no magnetic monopoles - all magnets must have two poles. Although some people are looking for magnetic monopoles, none have ever been observed, and if one is ever found, it will mean that Gauss' law for magnetism is incorrect.

\subsection{Faraday's law}

According to the definition of magnetic flux, \phib , a magnetic field passing through an area $A$ will create magnetic flux. Imagine that a circular loop of wire of radius $R$ is placed in a magnetic field $\vec{B}$, perpendicular to the direction of the field. The flux through the loop is clearly the strength of the magnetic field multiplied by the area of the loop: $\phib=\vec{B}\left(\pi R^2\right)$. Now imagine that the magnetic field began changing with time at a rate of $\displaystyle \frac{\dB}{\dt}$. The change in flux with time would be $\displaystyle \frac{\dphib}{dt}=\left(\pi R^2\right)\frac{\dB}{\dt}$. The flux could also be changed by altering the area of the loop, but since changing the area of the loop in real applications is not as practical as changing the magnetic field, and since the mathematics are largely similar, only the case of changing magnetic fields will be examined.

As was observed by Faraday, when \phib \ through the loop is changing, a voltage is \textit{induced} in the loop in an attempt by the system to ``fight'' the change. A current will then flow in the loop as determined by the Ohm's law, V=IR, where R is the resistance of the loop.

Consider again the scenario above. Faraday's law contains the integral of $\vec{E}\cdot\ds$. The \ds represents an infinitely small portion of the loop of wire. Recall that an electric field multiplied by a distance represents a voltage. We can go around the loop in either direction and it won't affect our results other than a change in sign - but that change in sign is to be expected, because in one direction, we would be increasing in potential as we went around, and in the other direction, we would be decreasing in potential! From Faraday's law, we have
\begin{eqnarray*}
\oint{\vec{E}\cdot\ds}&=&-\frac{\dphib}{dt}\\
\end{eqnarray*}
Since $\vec{E}$ in the wire will always be parallel to \ds, the dot product of the two will turn into simple multiplication. Furthermore, since $\vec{E}$ is not dependent on \ds, we can move $\vec{E}$ outside the integral, and simply have the integral of \ds, which is nothing but the perimeter of the loop, $2\pi R$. 
\begin{eqnarray*}
\vec{E}\oint{\ds}&=&-\frac{\dphib}{dt}\\
\vec{E}\left(2\pi R\right)&=&-\frac{\dphib}{dt}
\end{eqnarray*}

If, instead of having one loop of wire, we had $n$ loops, the ``area'' enclosed by the loop, while harder to visualize, would be $n$ times greater, and hence the change in flux would also be $n$ times greater, and the equation would become
\begin{eqnarray*}
\vec{E}\left(2\pi R\right)&=&-n\frac{\dphib}{dt}
\end{eqnarray*}

The negative sign in this equation is because of Lenz's Law, which essentially states that a negative sign is needed in this equation because otherwise it would be possible to violate Conservation of Energy. However, it only affects the direction of the current that flows because of the induced voltage, not the magnitude. Since the direction of the current is normally determined with a right hand rule, the negative sign can be ignored in the calculations without causing any serious consequences. The right hand rule for determining the direction of current goes as follows: point the thumb of the right hand in the direction of the changing flux. For example, if the magnetic field points up, and is decreasing, the thumb would be pointed down. If the field were increasing, the thumb would be pointed up. When this is done, the fingers of the right hand will curl in the direction of the flow of current in the loop.

\subsection{Ampere-Maxwell law}

Ampere observed that currrent flowing through a wire created a magnetic field around the wire, and formulated the equation
\begin{eqnarray}
\oint{\vec{B}\cdot\ds}&=&\muz i_{enc}
\end{eqnarray}

$i_{enc}$, meaning current enclosed, is perhaps a deceptive notation. Current can not be ``enclosed;'' rather, what is meant is the current that passes through the interior of the closed loop. \muz is a constant called the magnetic permeability of free space; if there is a material present instead of simply space, \muz is replaced with $\mu$ for the material.

Ampere's law is used by simply selecting any closed loop, traversing it with small elements \ds, and solving the resulting equation. It is key to note that \textit{any} closed loop can be selected - a flat disc, or perhaps a shape more similar to a grocery bag - and it will give the same results.

Ampere's law predicted the magnetic field very accurately, but Maxwell noticed that there was a piece missing. He noted that a capacitor is made of two conducting plates seperated by some distance $d$, and that while the capacitor was charging, positive charge accumulated on one plate, and negative charge accumulated on the other plate, but that no current passed between the plates. A capacitor is essentially a ``gap'' in a circuit, but because of its nature, the circuit is still complete. However, using Ampere's law to find the magnetic field at a point in space, it was possible to select one closed loop passing through the capacitor, so that no current passed through the closed loop. This would indicate that there was no magnetic field at that point. However, another closed loop could be selected for the same point that passed through one of the wires connected to the capacitor - the law leaves us free to choose our own closed loop - and since current flows in the wire, the law would clearly indicate that there \textit{was} a magnetic field at that point! Clearly this could not be, so something had to be missing.

Maxwell named the missing term ``displacement current,'' even though it is not really a current at all, but rather is the changing electric field within the capacitor. Since charge is accumulating on the plates of the capacitor, there is a changing electric field between the two plates. By introducing the term $\displaystyle\muz\eps0\frac{dphie}{dt}$, Maxwell completed the equation, now called the Ampere-Maxwell law:
\begin{eqnarray*}
\displaystyle\oint{\vec{B}\cdot\ds}&=&\muz\eps0\frac{\dphie}{\dt}+\muz i_{enc}
\end{eqnarray*}
When there is no changing electric field, $\displaystyle\frac{\dphie}{\dt}=0$ and the law simply becomes Ampere's law.

\section{Conclusion}

With his final addition to Ampere's law, and the formulation of the other three laws, Maxwell completed the theory of electricity and magnetism. Remarkably, using only the four equations known as Maxwell's equations, it is possible to explain \textit{all} known electromagnetic phenomena on the macroscopic scale. The equations helped Hertz discover and prove the existence of the radio wave; they are used frequently when designing anything that deals with electricity and magnetism, such as electronic motors and electromagnets; they have even led to research into quantum dynamics. Einstein claimed that Maxwell's equations led him toward the discovery of relativity, and many have called Maxwell the greatest scientist between Newton and Einstein.

While the equations may be difficult to understand, it is easy to see that they allow for the calculation of theoretical values for a myriad of different circuits, including motors, electromagnets that can pick up whole cars, and capacitor banks capable of storing enough power to run critical equipment for days in the case of a power failure. Maxwell and his equations forever changed the world in which we live.
\newpage
\nocite{Lewin}
\nocite{princeton}
\bibliography{bibliography}
\bibliographystyle{plain}

\end{document}